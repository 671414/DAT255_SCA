{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import List\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import os\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
    "from keras.src.backend.tensorflow.sparse import zeros_int8\n",
    "from tensorflow import Tensor"
   ],
   "id": "8edc991320962cf3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#må byttes med der du har lagret filene\n",
    "file_path = \"C:\\\\Users\\\\Kaspar\\\\ChipWhisperer5_64\\\\cw\\\\home\\\\portable\\\\chipwhisperer\\\\jupyter\\\\courses\\\\sca101\\\\training_set_new_kpts.hdf5\"\n",
    "with h5py.File(file_path, \"r\") as h5_file:\n",
    "    plaintext_set = h5_file['data'][:]\n",
    "    trace_set = h5_file['trace'][:]\n",
    "    key_set = h5_file['key'][:]\n",
    "    sub_byte_out_set = h5_file['sub_byte_out'][:]"
   ],
   "id": "2f4c5bd4963952ae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This is one of the few points where trace is manipulated, and the first place we will look for changes. Therefore we create a new array to contain in so we can always compare with the original",
   "id": "e9224c2d5801d9cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.plot(trace_set[0])\n",
    "plt.show()"
   ],
   "id": "5cd762e7ae74c07b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "scaled_trace_set = tf.keras.layers.Rescaling(1. / 127.5, offset=-1)(trace_set)\n",
    "scaled_trace_set = tf.expand_dims(scaled_trace_set, axis=-1)"
   ],
   "id": "d7d33f87bd206ed0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.plot(scaled_trace_set[0])\n",
    "plt.show()"
   ],
   "id": "7896997a20d0a66f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "h5_file.close()",
   "id": "74b574e8d9c20ab1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "trace_set.shape",
   "id": "2ffc7b6731cf2081"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "scaled_trace_set.shape",
   "id": "d46f745aa2c47dcc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(trace_set[0][35:45])\n",
    "plt.plot(trace_set[9][35:45])\n"
   ],
   "id": "10bb28d722974343"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#the numerical difference between the two traces on point 42:\n",
    "diff = trace_set[0][42] - trace_set[9][42]\n",
    "print(trace_set[0][42])\n",
    "print(trace_set[9][42])\n",
    "print(diff)"
   ],
   "id": "270f4dcb215d0857"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#testing if it holds through scaling\n",
    "scaled_diff = scaled_trace_set[0][42] - scaled_trace_set[9][42]\n",
    "print(scaled_trace_set[0][41:44])\n",
    "print(scaled_trace_set[9][41:44])\n",
    "print(scaled_diff)"
   ],
   "id": "48e2d1aeec85af49"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.plot(scaled_trace_set[0][35:45])\n",
    "plt.plot(scaled_trace_set[9][35:45])\n",
    "plt.plot(scaled_trace_set[5][35:45])\n",
    "print(scaled_trace_set[0][35:45])\n",
    "print(scaled_trace_set[5][35:45])\n",
    "print(plaintext_set[5])\n"
   ],
   "id": "c514b56a96997d80"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "looks pretty freaking close",
   "id": "5de453b92f19215e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4c9bd87e8c2dcbcf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First we create a dataset out of it, like i have done previously",
   "id": "58e511a6d5d8e18e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "num_traces = len(trace_set)\n",
    "num_bytes = 16\n",
    "sub_byte_in_set = np.zeros((num_traces, 16), dtype=np.uint8)\n",
    "\n",
    "for i in range(num_traces):\n",
    "    for byte_index in range(num_bytes):\n",
    "        pts=plaintext_set[i][byte_index] ^ key_set[i,byte_index]\n",
    "        sub_byte_in_set[i,byte_index] = pts\n",
    "#check if this works\n",
    "sub_byte_in_set = sub_byte_in_set"
   ],
   "id": "9e2417b1d63d090b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sub_byte_out = np.transpose(sub_byte_out_set, (1, 0))\n",
    "sub_byte_in = np.transpose(sub_byte_in_set, (1, 0))\n",
    "key = np.transpose(key_set, (1, 0))"
   ],
   "id": "ea71b8e3ba7c417"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "num_shards = 1\n",
    "num_traces_per_shard = 10\n",
    "file_path = \"\\\\...\\\\DAT255_SCA\\\\datasets\"\n",
    "\n",
    "#index to mark start and stop for slicing\n",
    "start_index = 0\n",
    "stop_index = num_traces_per_shard\n",
    "dataset_name = \"troubleshooting\" #change depending on the set you create\n",
    "\n",
    "#create a new h5py file that will contain the shards\n",
    "f = h5py.File(f\"{dataset_name}.hdf5\", \"w\")\n",
    "\n",
    "#Loop trough the dataset, creating groups for every key\n",
    "for i in range(num_shards):\n",
    "# create a group for each key, the name of the group will be the key in hex. This is refering to the original key\n",
    "#array, different indexing is needed if you want to use key\n",
    "    group_name = key_set[start_index].tobytes().hex()\n",
    "#Create one group representing a shard\n",
    "\n",
    "    group = f.create_group(group_name, track_order=True)\n",
    "#oppretter datasettene\n",
    "#rad, kolonne, steg vi vil ha alle rader, 256 kolonner av gangen. Også vurder å ta to categorical senere i prosessen\n",
    "#Må treffe på fordelingen her\n",
    "    group.create_dataset(\"traces\", data = scaled_trace_set[start_index:stop_index, :, :])\n",
    "    group.create_dataset(\"key\", data = key[:, start_index:stop_index])\n",
    "    group.create_dataset(\"sub_bytes_in\", data = sub_byte_in[:, start_index:stop_index])\n",
    "    group.create_dataset(\"sub_bytes_out\", data = sub_byte_out[:, start_index:stop_index])\n",
    "#må også ha trace slik at den kan hentes\n",
    "    start_index += num_traces_per_shard\n",
    "    stop_index += num_traces_per_shard\n",
    "f.close()"
   ],
   "id": "646c45504e029f69"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "When this is done we have one shard with 10 traces.",
   "id": "9c17171d1e7ec8a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2846425be96f49a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "f = h5py.File(f\"{dataset_name}.hdf5\", \"r\")\n",
    "i=0\n",
    "for group in f.keys():\n",
    "    print(group)\n",
    "    i+=1\n",
    "    print(i)\n",
    "    print()\n",
    "    for dset in f[group].keys():\n",
    "        print(dset)\n",
    "f.close()"
   ],
   "id": "e4952cf565a5f05b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "shard = []\n",
    "attack_byte = 0\n",
    "attack_point = \"sub_bytes_in\"\n",
    "max_trace_length = 5000\n",
    "num_traces = 10\n",
    "full_key = False\n",
    "x_List: List[Tensor] = []\n",
    "y_List: List[Tensor] = []\n",
    "\n",
    "#need to open the file to read any info\n",
    "with (h5py.File(f\"{dataset_name}.hdf5\", \"r\")) as f:\n",
    "    for group in f.keys():\n",
    "        group_name = f[group]\n",
    "\n",
    "        x_shard = group_name[\"traces\"][:num_traces_per_shard, :5000, :]\n",
    "        x_shard = tf.convert_to_tensor(x_shard, dtype=\"float32\")\n",
    "\n",
    "        y_shard = group_name[\"sub_bytes_in\"][attack_byte]\n",
    "        y_shard = y_shard[:num_traces_per_shard]\n",
    "        y_shard = tf.keras.utils.to_categorical(y_shard, 256)\n",
    "        y_shard = tf.convert_to_tensor(y_shard, dtype=\"uint8\")\n",
    "\n",
    "\n",
    "        x_List.append(x_shard)\n",
    "        y_List.append(y_shard)\n",
    "    x: Tensor = tf.concat(x_List, axis=0)\n",
    "    y: Tensor = tf.concat(y_List, axis=0)"
   ],
   "id": "ce95f453d6c80ae5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "x_train = x\n",
    "y_train = y"
   ],
   "id": "3d7a1821c16f8033"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "x_train.shape",
   "id": "8082686892f55688"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "y_train.shape",
   "id": "e8a737a3ae5e99e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(50, 40))\n",
    "plt.plot(x_train[0][40:45], label=\"Trace 0\",linewidth=2.5, color=\"black\")\n",
    "#plt.plot(x_train[1][40:45], label=\"Trace 1\",linewidth=2.5)\n",
    "#.plot(x_train[2][40:45], label=\"Trace 2\",linewidth=2.5)\n",
    "#plt.plot(x_train[3][40:45], label=\"Trace 3\",linewidth=2.5)\n",
    "plt.plot(x_train[4][40:45], label=\"Trace 4\",linewidth=2.5)\n",
    "plt.plot(x_train[5][40:45], label=\"Trace 5\",linewidth=2.5)\n",
    "plt.plot(x_train[6][40:45], label=\"Trace 6\",linewidth=2.5)\n",
    "plt.plot(x_train[7][40:45], label=\"Trace 7\",linewidth=2.5)\n",
    "plt.plot(x_train[8][40:45], label=\"Trace 8\",linewidth=2.5)\n",
    "plt.plot(x_train[9][40:45], label=\"Trace 9\",linewidth=2.5, color=\"red\")\n",
    "\n",
    "plt.title(\"traces\", fontsize=20)\n",
    "plt.legend(fontsize=30, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tick_params(axis='both', which='major', labelsize=14, width=2, length=6)  # Tykkere ticks\n",
    "plt.tick_params(axis='both', which='minor', length=4, width=1.5)\n",
    "\n",
    "plt.show()"
   ],
   "id": "7ad423b9922163a3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Vi kan se at trace 9, hvor verdien er 255 er det øverste, men det er faktisk ikke trace 0 hvor verdien er 0 som er det laveste.",
   "id": "7843f35d937c373b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Vi kan skrive ut byte 0 i hvert trace, og se om det er sammenheng mellom tall og plassering\n",
   "id": "afe84e3964b5d74d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Siden denne er gjort kategorisk går det selvfølgelig ikke, og vi må heller se på plaintext\n",
    "for i in range(len(plaintext_set)):\n",
    "    print(\"Plaintext: \", i, plaintext_set[i][:1])"
   ],
   "id": "2f7b43ab88231b22"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "735bc378637baab7"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
